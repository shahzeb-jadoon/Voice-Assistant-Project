# DeepSpeech

## Introduction:

[DeepSpeech](https://mycroft.ai/blog/deepspeech-update/) is an open source Speech-To-Text engine, using a model trained by machine learning techniques based on [Baidu's Deep Speech research paper](https://arxiv.org/pdf/1412.5567.pdf) and implemented with Googleâ€™s TensorFlow framework. [DeepSpeech's GitHub Repository](https://github.com/mozilla/DeepSpeech) can help you further understand the details of its workings.

## How To Get DeepSpeech:

Before we can attain DeepSpeech, we need to make sure we have certain requirements met so that DeepSpeech runs better. The first thing that is recommended is to have a Graphics Processing Units (GPU) especially if you want to train your own text-to-speech model using DeepSpeech. This [NVIDIA website](https://developer.nvidia.com/cuda-gpus) can tell you if your GPU is compatible. It is recommended that your GPU has a compute compatibility rating of 3.0 or higher. The higher the rating, the better/quicker you can train your model. The rating is of [CUDA-enabled GPU's](https://developer.nvidia.com/cuda-toolkit). 

[CUDA (Compute Unified Device Architecture)](http://www.techdarting.com/2013/06/cuda.html) is a [parallel computing](http://www.techdarting.com/2013/07/what-is-parallel-programming-why-do-you.html) platform and first programming model that enabled high level programming for GPUs and thereby made them available for general purpose computing. 

##
