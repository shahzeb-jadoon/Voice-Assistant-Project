FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -3.21797518312247499139e+00) (1, -2.44671657162653516382e-01) (2, -1.48792541998373578638e-01) (3, -1.58655560987936566919e-01) (4, -6.72826314744821574187e-02) (5, 5.76722036039723384704e-01) (6, 7.36077376885269973883e-01) (7, 8.01177431931315409130e-01) (8, 3.00005386802444373728e-01) (9, 4.96935823763109074669e-01) (10, 5.87447153295501747761e-02) (0, -3.25288136928590043695e+00) (1, -2.28949469968026203537e-01) (2, -1.32682395621483845138e-01) (3, -2.63422788574641186798e-01) (4, -2.01103543385212940597e-01) (5, 4.88574745988739900238e-01) (6, 8.66337572838759784055e-01) (7, 7.49635209431467774976e-01) (8, 2.45782020720729799113e-01) (9, 5.05091624165273644920e-01) (10, 3.72952775858707494261e-02) (0, 5.70555130564751378230e-01) (1, 6.11750315873276884204e-01) (2, 4.69285611061703966662e-01) (3, 6.59102823583733732349e-01) (4, 5.23581925778042966968e-01) (5, 1.59016444920776423011e+00) (6, -1.08784020437122408431e+00) (7, 1.15704881835529160838e+00) (8, 4.39254937798399591742e+00) (9, 4.79791039061204216409e+00) (10, -1.58060212965468099844e-01) (0, 5.89730227911057225398e-01) (1, 5.01276586203229235217e-01) (2, 6.55278172342431242114e-01) (3, 6.54320057479989225513e-01) (4, 4.74657166747700975939e-01) (5, 1.51636160361832872390e+00) (6, -1.04238745315195147079e+00) (7, 1.04918104845830706395e+00) (8, 4.31432194740194940863e+00) (9, 4.80845695566788933206e+00) (10, -1.95310374136427572500e-01) (0, -1.19914803520323620667e+00) (1, -2.52526655077745076916e-01) (2, -3.75375478744317647717e-01) (3, -3.55527094781209584973e-01) (4, -3.15654575109292623303e-01) (5, 5.40885116567677681765e-01) (6, 9.04874434377646696959e-01) (7, 7.34976512481985810865e-01) (8, 4.70206851482876275750e-01) (9, 6.27506535880600013755e-01) (10, 3.48383662864151344429e-01) (0, 6.03491342240156880550e-01) (1, 6.49122934786927396900e-01) (2, 4.70354143528592394397e-01) (3, 4.98624492435109423205e-01) (4, 5.28671611098897153980e-01) (5, 1.58537250398872431312e+00) (6, -1.01451801998735491317e+00) (7, 1.17602565575191331249e+00) (8, 4.44808969379086160956e+00) (9, 4.85296778213635704446e+00) (10, -3.21467561061838769110e-01) (0, 1.66986524904348576648e+00) (1, 3.09565737259925866098e-01) (2, 1.74066762787641521326e-01) (3, 1.55517845762313838831e-01) (4, 2.34567172241748805872e-01) (5, -8.13457746806986459198e-02) (6, -1.25875164696831864930e+00) (7, -3.88023539121884641911e-01) (8, -4.97856796355187591896e-01) (9, -5.72968833135217403552e-01) (10, 1.04319253055835059474e-01) (0, 1.70340779812984477459e+00) (1, 7.29778506254925574126e-01) (2, 7.19487779235615576567e-01) (3, 5.74356891608013953032e-01) (4, 7.05187462663426245513e-01) (5, 1.50166907589721088101e+00) (6, -1.09608519567371431869e+00) (7, 1.05632619692254592358e+00) (8, 3.66027427474706046340e+00) (9, 4.78516170960322639871e+00) (10, -6.11618887551733436680e-01) (0, -8.30641676535366246803e-01) (1, 1.08354577608385571619e-01) (2, 1.51839295215883768320e-01) (3, 6.21218698099045979477e-02) (4, 6.12254308536439167954e-02) (5, 6.74263519018876378297e-01) (6, 2.62053493209384258389e-01) (7, 8.56781540279380027236e-01) (8, -3.33910649521772462389e-01) (9, 7.79017814284228005128e-01) (10, 1.73797068925936076811e-01) (0, 1.77605518183189953207e-01) (1, -1.05823242221759872272e-01) (2, -5.61449036447912719350e-03) (3, -3.86493012754827872449e-03) (4, -4.28750227436295108796e-02) (5, -1.66346257581963108407e+00) (6, -3.64392966219924285820e-01) (7, -1.35932791190928803360e+00) (8, 1.23472901347688601703e+00) (9, -5.63806893645255780001e+00) (10, -1.54871865793023505420e-01) (11, 6.82787273511827885741e-01) (12, 6.61346722826898991698e-01) (13, 4.60045015336289886410e-01) (14, 4.94298687101617340023e-01) (15, 7.32650403366030156249e-01) (16, 4.08574176849141601497e-01) (17, -3.11496492903677868469e-01) (18, 4.89818146349206451351e-01) (19, 1.72883902004509232286e-01) (20, -6.63844869119067926277e-02) (21, 4.02336334936673811757e-01) 
