FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 8.24225823668961882218e-02) (1, 1.06168331361347640512e-02) (2, 1.94787399535714493559e-03) (3, 4.45675195909076837797e-02) (4, -1.30481628909057928434e-01) (5, 3.86322684064358656819e-01) (6, 1.20108634629582947118e-01) (7, 1.88429564591142184593e-01) (8, 4.39580613159706812265e-01) (9, 1.23371817483641801894e-01) (10, -1.69429759065066409818e-01) (0, -3.48093783884395469030e+00) (1, -5.65396761254287061327e-01) (2, -4.78584943071818702531e-01) (3, -5.03583056584811838974e-01) (4, -6.34474327520346714770e-01) (5, 7.97465803710013965144e+00) (6, 3.28431513849749334710e-01) (7, -1.88291515399518105678e-01) (8, 5.98081250795279406596e-01) (9, 2.17305308896364612892e+00) (10, 1.76013773766855646796e-01) (0, 1.59508289511573941866e+01) (1, 3.72907589771495961983e-01) (2, 4.89790130057083272774e-01) (3, 3.21038771071182393868e-01) (4, 3.05003802873836604714e-01) (5, -1.28625262467625267604e+00) (6, -1.17773101270492652759e+00) (7, 7.47702594871076375860e-02) (8, -2.61913545921952772844e+00) (9, -4.02200739640153859256e+00) (10, 3.81399690282411996112e-01) (0, -1.59111726171960843335e-01) (1, -2.94570868408509899117e-02) (2, -4.08503507768937651479e-02) (3, 7.10125396454504148602e-02) (4, 2.62629071676900825716e-02) (5, -4.59009830594254042424e-01) (6, 3.94127565426238446467e-01) (7, 1.94581156006112060419e-01) (8, -6.78963352680257536953e-01) (9, -2.05267899909771983635e-01) (10, -3.42419132633837303148e-02) (0, -3.94979387238926560322e-01) (1, -2.14366488573939396878e-02) (2, -4.91804652331263442155e-02) (3, -9.48115293363642128166e-03) (4, 8.21078620435802680744e-02) (5, -4.86724160907062219916e-01) (6, 3.63020646376021771662e-01) (7, 2.60612656703247957957e-01) (8, -5.51689606845430113857e-01) (9, -7.63067210800639356139e-02) (10, -1.72263959194659671548e-01) (0, 3.50734869329825871276e+00) (1, 3.61220787117367936325e-01) (2, 3.06355940947419358444e-01) (3, 2.81434594491606904221e-01) (4, 3.66426179954892350388e-01) (5, -6.96816552663421795444e+00) (6, 8.37997558621781912791e+00) (7, 4.90675107915343033937e+00) (8, 1.64548582903507711883e-01) (9, 5.35126295447196742572e+00) (10, -1.06511113472589369344e+00) (0, 1.77236659386587669385e-01) (1, 1.61855994499982350221e-02) (2, -7.05850840769946114017e-02) (3, -2.99325705729662772114e-02) (4, -2.13983924351870413716e-02) (5, 3.50201734055816393809e-01) (6, 2.14607874605827225745e-01) (7, 3.17736122567381720772e-02) (8, 4.06128258788159113291e-01) (9, 2.25519995746455176322e-01) (10, 6.49941174756124562251e-02) (0, 8.66370157568923549007e-01) (1, 2.96182306432162777143e-02) (2, 4.99214352988634965658e-02) (3, 4.37746318005953830022e-02) (4, -3.90726728416050869686e-02) (5, 6.82106575848085983083e-01) (6, 7.46187187055317585616e-02) (7, 1.74625724226106365800e-02) (8, -1.36451122488415343970e-01) (9, 1.08749280844243859101e-01) (10, -1.79122566399178284602e-02) (0, -9.47877504399888964892e-02) (1, 6.91805157814412013950e-02) (2, 1.16120774302868740024e-02) (3, -2.41167124356836994059e-02) (4, 3.52947909388928449115e-02) (5, -1.64699115250604788407e+00) (6, 1.97251619528734628561e-01) (7, 2.82346922325511451302e-01) (8, -6.60382463594743396307e-01) (9, -1.95292997184184830006e-01) (10, -2.23582357069665033089e-02) (0, -1.28991062827100794186e-01) (1, 5.48038973106246135591e-02) (2, -1.08612041305174308881e-01) (3, -1.83199973212380302912e-02) (4, -4.74900318252038326078e-03) (5, -3.28025628094378796096e-01) (6, -5.26294815465957604994e-02) (7, -1.02639256102988532526e-01) (8, -2.96641690502824961762e-01) (9, -4.89756070115337366344e-03) (10, -1.76847423733062697471e-01) (11, 4.00551844393783218479e-01) (12, 6.16635619407846502504e-01) (13, -5.22177648249053993901e-01) (14, -4.29453727395922302268e-02) (15, -1.46294482419727728262e-01) (16, 5.32411673029614118668e-01) (17, 4.77049081084344628323e-01) (18, 5.63408696526034535879e-01) (19, -1.41337116393064399222e-01) (20, -1.56336267320197785935e-01) (21, 2.82537629383449284681e-01) 
